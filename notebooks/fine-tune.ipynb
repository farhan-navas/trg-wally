{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# OpenAI Fine-Tuning API\n",
    "Detailed process of how I will be using OpenAI fine-tuning API for Wally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create instance of OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup\n",
    "\n",
    "For this section we will compile all our word doc datasets into jsonl files which the OpenAI API requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted advice-1.docx into a convo of 5 messages\n",
      "Converted advice-10.docx into a convo of 3 messages\n",
      "Converted advice-2.docx into a convo of 3 messages\n",
      "Converted advice-3.docx into a convo of 5 messages\n",
      "Converted advice-4.docx into a convo of 5 messages\n",
      "Converted advice-6.docx into a convo of 5 messages\n",
      "Converted advice-7.docx into a convo of 3 messages\n",
      "Converted advice-8.docx into a convo of 9 messages\n",
      "Converted advice-9.docx into a convo of 5 messages\n",
      "✅ Wrote 9 conversations to ../data/processed/chinese/reddit/advice.json\n",
      "Converted advice-1.docx into a convo of 5 messages\n",
      "Converted advice-10.docx into a convo of 3 messages\n",
      "Converted advice-2.docx into a convo of 3 messages\n",
      "Converted advice-3.docx into a convo of 5 messages\n",
      "Converted advice-4.docx into a convo of 5 messages\n",
      "Converted advice-6.docx into a convo of 5 messages\n",
      "Converted advice-7.docx into a convo of 3 messages\n",
      "Converted advice-8.docx into a convo of 9 messages\n",
      "Converted advice-9.docx into a convo of 5 messages\n",
      "✅ Wrote 9 conversations to ../data/processed/english/reddit/advice.json\n",
      "[json_to_jsonl] converted ../data/processed/chinese/reddit/advice.json to ../data/processed/chinese/reddit/advice.jsonl\n",
      "[json_to_jsonl] converted ../data/processed/english/reddit/advice.json to ../data/processed/english/reddit/advice.jsonl\n",
      "Converted dating-advice-1.docx into a convo of 3 messages\n",
      "Converted dating-advice-2.docx into a convo of 4 messages\n",
      "Converted dating-advice-3.docx into a convo of 7 messages\n",
      "Converted dating-advice-4.docx into a convo of 5 messages\n",
      "Converted dating-advice-5.docx into a convo of 5 messages\n",
      "Converted dating-advice-6.docx into a convo of 5 messages\n",
      "Converted dating-advice-7.docx into a convo of 5 messages\n",
      "Converted dating-advice-8.docx into a convo of 5 messages\n",
      "✅ Wrote 8 conversations to ../data/processed/chinese/reddit/dating-advice.json\n",
      "Converted dating-advice-1.docx into a convo of 5 messages\n",
      "Converted dating-advice-2.docx into a convo of 5 messages\n",
      "Converted dating-advice-3.docx into a convo of 7 messages\n",
      "Converted dating-advice-4.docx into a convo of 5 messages\n",
      "Converted dating-advice-5.docx into a convo of 5 messages\n",
      "Converted dating-advice-6.docx into a convo of 5 messages\n",
      "Converted dating-advice-7.docx into a convo of 5 messages\n",
      "Converted dating-advice-8.docx into a convo of 5 messages\n",
      "✅ Wrote 8 conversations to ../data/processed/english/reddit/dating-advice.json\n",
      "[json_to_jsonl] converted ../data/processed/chinese/reddit/dating-advice.json to ../data/processed/chinese/reddit/dating-advice.jsonl\n",
      "[json_to_jsonl] converted ../data/processed/english/reddit/dating-advice.json to ../data/processed/english/reddit/dating-advice.jsonl\n",
      "Converted relationship-advice-chi-1.docx into a convo of 5 messages\n",
      "Converted relationship-advice-chi-10.docx into a convo of 3 messages\n",
      "Converted relationship-advice-chi-2.docx into a convo of 7 messages\n",
      "Converted relationship-advice-chi-3.docx into a convo of 7 messages\n",
      "Converted relationship-advice-chi-4.docx into a convo of 5 messages\n",
      "Converted relationship-advice-chi-5.docx into a convo of 7 messages\n",
      "Converted relationship-advice-chi-6.docx into a convo of 5 messages\n",
      "Converted relationship-advice-chi-7.docx into a convo of 4 messages\n",
      "Converted relationship-advice-chi-8.docx into a convo of 5 messages\n",
      "Converted relationship-advice-chi-9.docx into a convo of 5 messages\n",
      "✅ Wrote 10 conversations to ../data/processed/chinese/reddit/relationship-advice.json\n",
      "Converted relationship-advice-1.docx into a convo of 5 messages\n",
      "Converted relationship-advice-10.docx into a convo of 3 messages\n",
      "Converted relationship-advice-2.docx into a convo of 7 messages\n",
      "Converted relationship-advice-3.docx into a convo of 7 messages\n",
      "Converted relationship-advice-4.docx into a convo of 5 messages\n",
      "Converted relationship-advice-5.docx into a convo of 7 messages\n",
      "Converted relationship-advice-6.docx into a convo of 5 messages\n",
      "Converted relationship-advice-7.docx into a convo of 5 messages\n",
      "Converted relationship-advice-8.docx into a convo of 5 messages\n",
      "Converted relationship-advice-9.docx into a convo of 5 messages\n",
      "✅ Wrote 10 conversations to ../data/processed/english/reddit/relationship-advice.json\n",
      "[json_to_jsonl] converted ../data/processed/chinese/reddit/relationship-advice.json to ../data/processed/chinese/reddit/relationship-advice.jsonl\n",
      "[json_to_jsonl] converted ../data/processed/english/reddit/relationship-advice.json to ../data/processed/english/reddit/relationship-advice.jsonl\n",
      "✅ Wrote 0 conversations to ../data/processed/chinese/reddit/ask-singapore.json\n",
      "Converted ask-singapore-3.docx into a convo of 8 messages\n",
      "Converted ask-singapore-4.docx into a convo of 9 messages\n",
      "Converted ask-singapore-5.docx into a convo of 7 messages\n",
      "Converted ask-singapore-6.docx into a convo of 8 messages\n",
      "Converted ask-singapore-7.docx into a convo of 11 messages\n",
      "Converted ask-singapore-8.docx into a convo of 7 messages\n",
      "✅ Wrote 6 conversations to ../data/processed/english/reddit/ask-singapore.json\n",
      "[json_to_jsonl] converted ../data/processed/chinese/reddit/ask-singapore.json to ../data/processed/chinese/reddit/ask-singapore.jsonl\n",
      "[json_to_jsonl] converted ../data/processed/english/reddit/ask-singapore.json to ../data/processed/english/reddit/ask-singapore.jsonl\n",
      "✅ Wrote 0 conversations to ../data/processed/chinese/reddit/work-advice.json\n",
      "Converted work-advice-1.docx into a convo of 9 messages\n",
      "Converted work-advice-10.docx into a convo of 8 messages\n",
      "Converted work-advice-11.docx into a convo of 9 messages\n",
      "Converted work-advice-12.docx into a convo of 7 messages\n",
      "Converted work-advice-13.docx into a convo of 7 messages\n",
      "Converted work-advice-14.docx into a convo of 7 messages\n",
      "Converted work-advice-15.docx into a convo of 11 messages\n",
      "Converted work-advice-16.docx into a convo of 11 messages\n",
      "Converted work-advice-17.docx into a convo of 7 messages\n",
      "Converted work-advice-18.docx into a convo of 7 messages\n",
      "Converted work-advice-19.docx into a convo of 10 messages\n",
      "Converted work-advice-2.docx into a convo of 5 messages\n",
      "Converted work-advice-3.docx into a convo of 3 messages\n",
      "Converted work-advice-4.docx into a convo of 5 messages\n",
      "Converted work-advice-5.docx into a convo of 8 messages\n",
      "Converted work-advice-6.docx into a convo of 7 messages\n",
      "Converted work-advice-7.docx into a convo of 11 messages\n",
      "Converted work-advice-8.docx into a convo of 8 messages\n",
      "Converted work-advice-9.docx into a convo of 8 messages\n",
      "✅ Wrote 19 conversations to ../data/processed/english/reddit/work-advice.json\n",
      "[json_to_jsonl] converted ../data/processed/chinese/reddit/work-advice.json to ../data/processed/chinese/reddit/work-advice.jsonl\n",
      "[json_to_jsonl] converted ../data/processed/english/reddit/work-advice.json to ../data/processed/english/reddit/work-advice.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Import necessary conversion util scripts\n",
    "from scripts.docs.docx_to_json import convert_docx_folder_to_json\n",
    "from scripts.utils.json_to_jsonl import convert_to_jsonl\n",
    "\n",
    "# Word doc setup\n",
    "docx_folder_patterns = ['advice', 'dating-advice', 'relationship-advice', 'ask-singapore', 'work-advice']\n",
    "data_folder_path_cn = \"../data/processed-word-docs/chinese/reddit\"\n",
    "data_folder_path_el = \"../data/processed-word-docs/english/reddit\"\n",
    "\n",
    "output_cn = \"../data/processed/chinese\"\n",
    "output_el = \"../data/processed/english\"\n",
    "\n",
    "# Convert all relevant data into jsonl format\n",
    "for p in docx_folder_patterns:\n",
    "    cn_path = f\"{data_folder_path_cn}/{p}/{p}-*.docx\"\n",
    "    el_path = f\"{data_folder_path_el}/{p}/{p}-*.docx\"\n",
    "\n",
    "    cn_out = f\"{output_cn}/reddit/{p}.json\"\n",
    "    el_out = f\"{output_el}/reddit/{p}.json\"\n",
    "\n",
    "    convert_docx_folder_to_json(docx_folder_pattern=cn_path, output_json=cn_out)\n",
    "    convert_docx_folder_to_json(docx_folder_pattern=el_path, output_json=el_out)\n",
    "\n",
    "    convert_to_jsonl(input_path=cn_out, output_path=f\"{cn_out}l\")\n",
    "    convert_to_jsonl(input_path=el_out, output_path=f\"{el_out}l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[merge_files] found 3 files matching pattern: '../data/processed/chinese/reddit/*.jsonl'\n",
      "[merge_files] ✅ merge complete, output file: '../data/processed/chinese/run-one-chi.jsonl'\n",
      "[merge_files] found 5 files matching pattern: '../data/processed/english/reddit/*.jsonl'\n",
      "[merge_files] ✅ merge complete, output file: '../data/processed/english/run-one-eng.jsonl'\n"
     ]
    }
   ],
   "source": [
    "# Create one training file each for english and chinese\n",
    "from scripts.utils.combine_jsonl import merge_files\n",
    "\n",
    "fin_cn = f\"{output_cn}/reddit/*.jsonl\"\n",
    "fin_el = f\"{output_el}/reddit/*.jsonl\"\n",
    "\n",
    "fout_cn = f\"{output_cn}/run-one-chi.jsonl\"\n",
    "fout_el = f\"{output_el}/run-one-eng.jsonl\"\n",
    "\n",
    "merge_files(pattern=fin_cn, output_path=fout_cn)\n",
    "merge_files(pattern=fin_el, output_path=fout_el)\n",
    "training_files = [fout_cn, fout_el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload files\n",
    "Use `client.files.create()` method from OpenAI Files API to upload training file (for now only training, no validation) to OpenAI API. Afterwards, store returned File object ID for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID for run-one-chi.jsonl: file-QcSqFB9dtxf7WAxiTMuQRY\n",
      "Training file ID for run-one-eng.jsonl: file-NaRw4gN9FXeoQMdJy4Edqk\n"
     ]
    }
   ],
   "source": [
    "training_file_ids = []\n",
    "for ff in training_files:\n",
    "    training_file = client.files.create(\n",
    "        file=open(ff, \"rb\"),\n",
    "        purpose=\"fine-tune\",\n",
    "    )\n",
    "\n",
    "    training_file_ids.append(training_file.id)\n",
    "    print(f\"Training file ID for {ff.split(\"/\")[-1]}: {training_file.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fine-tuning job\n",
    "Use the `client.fine_tuning.jobs.create()` method to create a fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID for ../data/processed/chinese/run-one-chi.jsonl: ftjob-o0w6sinf3Rhlw9j4khHy2Vd2\n",
      "Job status for ../data/processed/chinese/run-one-chi.jsonl: validating_files\n",
      "Job ID for ../data/processed/english/run-one-eng.jsonl: ftjob-LYiTCGL02DPqBztXmjqSgFyW\n",
      "Job status for ../data/processed/english/run-one-eng.jsonl: validating_files\n"
     ]
    }
   ],
   "source": [
    "job_ids = []\n",
    "for idx, id in enumerate(training_file_ids):\n",
    "    job = client.fine_tuning.jobs.create(\n",
    "        training_file=id,\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        suffix=\"wally\",\n",
    "    )\n",
    "\n",
    "    job_ids.append(job.id)\n",
    "    print(f\"Job ID for {training_files[idx].split(\"/\")[-1]}: {job.id}\")\n",
    "    print(f\"Job status for {training_files[idx].split(\"/\")[-1]}: {job.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Job Status\n",
    "Check status using `client.fine_tuning.jobs.retrieve() ` method, which takes in job ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-o0w6sinf3Rhlw9j4khHy2Vd2\n",
      "Job status: failed\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Trained Tokens: None \n",
      "\n",
      "Job ID: ftjob-LYiTCGL02DPqBztXmjqSgFyW\n",
      "Job status: failed\n",
      "Model: gpt-4o-mini-2024-07-18\n",
      "Trained Tokens: None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, id in enumerate(job_ids):\n",
    "    retrieve_response = client.fine_tuning.jobs.retrieve(id)\n",
    "\n",
    "    print(f\"Job ID: {retrieve_response.id}\")\n",
    "    print(f\"Job status: {retrieve_response.status}\")\n",
    "    print(f\"Model: {retrieve_response.model}\")\n",
    "    print(f\"Trained Tokens: {retrieve_response.trained_tokens} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List events of the job using the `client.fine_tuning.jobs.list_events()` method. Returns a list of events associated with the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.15\n",
      "Step 86/100: training loss=1.26\n",
      "Step 87/100: training loss=1.35\n",
      "Step 88/100: training loss=0.01\n",
      "Step 89/100: training loss=0.64\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.19\n",
      "Step 92/100: training loss=0.93\n",
      "Step 93/100: training loss=0.22\n",
      "Step 94/100: training loss=0.27\n",
      "Step 95/100: training loss=1.63\n",
      "Step 96/100: training loss=0.38\n",
      "Step 97/100: training loss=1.16\n",
      "Step 98/100: training loss=0.15\n",
      "Step 99/100: training loss=0.52\n",
      "Step 100/100: training loss=1.21\n",
      "Checkpoint created at step 50\n",
      "Checkpoint created at step 75\n",
      "New fine-tuned model created\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
